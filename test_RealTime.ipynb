{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863460f6",
   "metadata": {},
   "source": [
    "## Test in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c18cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8e04e",
   "metadata": {},
   "source": [
    "- preapering for reading keypoints using mp holistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa255d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS WORKING WITH MP HOLISTIC MODEL\n",
    "\n",
    "# Initialazing mp holistic for keypoints\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "\n",
    "\n",
    "# Finding landmarks with model holistic\n",
    "def mediapipe_detection(image, model):\n",
    "    \n",
    "    # creating contrast on img\n",
    "    lab= cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) # applying CLAHE to L-channel   - feel free to try different values for the limit and grid size\n",
    "    cl = clahe.apply(l_channel)\n",
    "    limg = cv2.merge((cl,a,b)) # merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    image = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR) #onverting image from LAB Color model to BGR color spcae\n",
    "    \n",
    "    # detections\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # color conversion BGR 2 RGB\n",
    "    image.flags.writeable = False                  # image is no longer writeable\n",
    "    results = model.process(image)                 # make prediction\n",
    "    image.flags.writeable = True                   # image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # color conversion RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "\n",
    "\n",
    "# Drawing landmarks\n",
    "def draw_styled_landmarks(image, results):\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) # draw pose connections\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) # draw left hand connections\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) # draw right hand connections  \n",
    "\n",
    "    \n",
    "    \n",
    "# Preparing vector of date\n",
    "def extract_keypoints(results):\n",
    "    \n",
    "    if (results.pose_landmarks == None): # if there is no landmarks\n",
    "        return [], [], [], [], [],\n",
    "        \n",
    "    else:\n",
    "        # face\n",
    "        x = 0\n",
    "        y = 0\n",
    "        for i in range(11):\n",
    "            if results.pose_landmarks.landmark[i].visibility > 0.95:\n",
    "                x += results.pose_landmarks.landmark[i].x\n",
    "                y += results.pose_landmarks.landmark[i].y\n",
    "            else:\n",
    "                return [], [], [], [], [],\n",
    "        face = np.array([x/11, y/11]) # the middle point from all points on face\n",
    "        \n",
    "        \n",
    "        # pose\n",
    "        pose_left = []\n",
    "        pose_right = []\n",
    "        \n",
    "        if(results.pose_landmarks.landmark[11].visibility > 0.85 and results.pose_landmarks.landmark[12].visibility > 0.85): # middle point between choulders\n",
    "            pose_left.append(((results.pose_landmarks.landmark[11].x + results.pose_landmarks.landmark[12].x) /2) - face[0])\n",
    "            pose_left.append(((results.pose_landmarks.landmark[11].y + results.pose_landmarks.landmark[12].y) /2) - face[1])\n",
    "            pose_right.append(((results.pose_landmarks.landmark[11].x + results.pose_landmarks.landmark[12].x) /2) - face[0])\n",
    "            pose_right.append(((results.pose_landmarks.landmark[11].y + results.pose_landmarks.landmark[12].y) /2) - face[1])\n",
    "        else:\n",
    "            pose_left.append(0)\n",
    "            pose_left.append(0)\n",
    "            pose_right.append(0)\n",
    "            pose_right.append(0)\n",
    "\n",
    "        for i in range(11, 17): # points from pose - arms and shoulder\n",
    "            if(results.pose_landmarks.landmark[i].visibility > 0.85):\n",
    "                if(i % 2 == 0):\n",
    "                    pose_right.append(results.pose_landmarks.landmark[i].x - face[0])\n",
    "                    pose_right.append(results.pose_landmarks.landmark[i].y - face[1])\n",
    "                else:     \n",
    "                    pose_left.append(results.pose_landmarks.landmark[i].x - face[0])\n",
    "                    pose_left.append(results.pose_landmarks.landmark[i].y - face[1])\n",
    "            else:\n",
    "                if(i % 2 == 0):\n",
    "                    pose_right.append(0)\n",
    "                    pose_right.append(0) \n",
    "                else:\n",
    "                    pose_left.append(0)\n",
    "                    pose_left.append(0)     \n",
    "\n",
    "        pose_left = np.array(pose_left)\n",
    "        pose_right = np.array(pose_right)\n",
    "\n",
    "        \n",
    "        # right hand\n",
    "        if (results.right_hand_landmarks == None):\n",
    "            right_hand = []\n",
    "        else:\n",
    "            right_hand = np.array([[-1 * (res.x - face[0]), res.y - face[1]] for res in results.right_hand_landmarks.landmark]).flatten()\n",
    "\n",
    "            \n",
    "        # left hand\n",
    "        if (results.left_hand_landmarks == None):\n",
    "            left_hand = []\n",
    "        else:\n",
    "            left_hand = np.array([[res.x - face[0], res.y - face[1]] for res in results.left_hand_landmarks.landmark]).flatten()\n",
    "   \n",
    "\n",
    "        return face, pose_left, pose_right, left_hand, right_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484e26d",
   "metadata": {},
   "source": [
    "- preapering video sequence for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f84420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR extract_sequence\n",
    "\n",
    "def init_global_variables_on_zero(all_variables = True):\n",
    "    \n",
    "    global frame_num, all_keypoints, left_zeros_fixed, right_zeros_fixed\n",
    "    global number_of_blank_pose_left, number_of_blank_pose_right, number_of_blank_left_hand, number_of_blank_right_hand\n",
    "    global vector_of_blank_pose_left, vector_of_blank_pose_right, vector_of_blank_left_hand, vector_of_blank_right_hand\n",
    "    global all_frames_pose_left, all_frames_pose_right, all_frames_left_hand, all_frames_right_hand\n",
    "    \n",
    "    \n",
    "    number_of_blank_pose_left = 0\n",
    "    number_of_blank_pose_right = 0\n",
    "    number_of_blank_left_hand = 0\n",
    "    number_of_blank_right_hand = 0\n",
    "    \n",
    "    vector_of_blank_pose_left = []\n",
    "    vector_of_blank_pose_right = []\n",
    "    vector_of_blank_left_hand = []\n",
    "    vector_of_blank_right_hand = []\n",
    "    \n",
    "    if all_variables:\n",
    "        all_frames_pose_left = []\n",
    "        all_frames_pose_right = []\n",
    "        all_frames_left_hand = []\n",
    "        all_frames_right_hand = []\n",
    "        \n",
    "        frame_num = 1\n",
    "        all_keypoints = []\n",
    "        left_zeros_fixed = False\n",
    "        right_zeros_fixed = False\n",
    "        \n",
    "\n",
    "        \n",
    "def counting_number_of_blanks():\n",
    "    \n",
    "    global frame_num, all_keypoints, left_zeros_fixed, right_zeros_fixed\n",
    "    global number_of_blank_pose_left, number_of_blank_pose_right, number_of_blank_left_hand, number_of_blank_right_hand\n",
    "    global vector_of_blank_pose_left, vector_of_blank_pose_right, vector_of_blank_left_hand, vector_of_blank_right_hand\n",
    "    global all_frames_pose_left, all_frames_pose_right, all_frames_left_hand, all_frames_right_hand\n",
    "    global pose_left, pose_right, left_hand, right_hand\n",
    "    \n",
    "    \n",
    "    # checking existence of landmarks on body and hands\n",
    "    if len(left_hand) == 0:\n",
    "        left_hand = np.zeros(42)\n",
    "        vector_of_blank_left_hand.append(1)\n",
    "    else:\n",
    "        vector_of_blank_left_hand.append(0)\n",
    "        \n",
    "    if len(right_hand) == 0:\n",
    "        right_hand = np.zeros(42)\n",
    "        vector_of_blank_right_hand.append(1)\n",
    "    else:\n",
    "        vector_of_blank_right_hand.append(0)\n",
    "        \n",
    "    if len(pose_left) - np.count_nonzero(pose_left) != 0:\n",
    "        vector_of_blank_pose_left.append(1)\n",
    "    else:\n",
    "        vector_of_blank_pose_left.append(0)\n",
    "            \n",
    "    if len(pose_right) - np.count_nonzero(pose_right) != 0:\n",
    "        vector_of_blank_pose_right.append(1)\n",
    "    else:\n",
    "        vector_of_blank_pose_right.append(0)\n",
    "            \n",
    "    # number of blanks in last 12 frames not including last one\n",
    "    if (frame_num > sequence_length):\n",
    "        vector_of_blank_pose_left = vector_of_blank_pose_left[-13:-1]\n",
    "        vector_of_blank_pose_right = vector_of_blank_pose_right[-13:-1]\n",
    "        vector_of_blank_left_hand = vector_of_blank_left_hand[-13:-1]\n",
    "        vector_of_blank_right_hand = vector_of_blank_right_hand[-13:-1]\n",
    "            \n",
    "    number_of_blank_pose_left = sequence_length - np.count_nonzero(vector_of_blank_pose_left)\n",
    "    number_of_blank_pose_right = sequence_length - np.count_nonzero(vector_of_blank_pose_right)\n",
    "    number_of_blank_left_hand = sequence_length - np.count_nonzero(vector_of_blank_left_hand)\n",
    "    number_of_blank_right_hand = sequence_length - np.count_nonzero(vector_of_blank_right_hand)\n",
    "    \n",
    "\n",
    "\n",
    "# Updating hole story for single part \n",
    "def update_all_frames():\n",
    "    \n",
    "    global frame_num, all_keypoints, left_zeros_fixed, right_zeros_fixed\n",
    "    global number_of_blank_pose_left, number_of_blank_pose_right, number_of_blank_left_hand, number_of_blank_right_hand\n",
    "    global vector_of_blank_pose_left, vector_of_blank_pose_right, vector_of_blank_left_hand, vector_of_blank_right_hand\n",
    "    global all_frames_pose_left, all_frames_pose_right, all_frames_left_hand, all_frames_right_hand\n",
    "    global pose_left, pose_right, left_hand, right_hand\n",
    "    \n",
    "    \n",
    "    all_frames_pose_left.append(pose_left)\n",
    "    all_frames_pose_right.append(pose_right)\n",
    "    all_frames_left_hand.append(left_hand)\n",
    "    all_frames_right_hand.append(right_hand)\n",
    "    \n",
    "    # extracting last 13 frames\n",
    "    if (frame_num > sequence_length):\n",
    "        all_frames_pose_left = all_frames_pose_left[-13:]\n",
    "        all_frames_pose_right = all_frames_pose_right[-13:]\n",
    "        all_frames_left_hand = all_frames_left_hand[-13:]\n",
    "        all_frames_right_hand = all_frames_right_hand[-13:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbccfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixing_zeros_and_counting_varations(all_frames_part, check_varation = True, fix_zeros = True):  \n",
    "    \n",
    "    global frame_num, all_keypoints, left_zeros_fixed, right_zeros_fixed\n",
    "    global number_of_blank_pose_left, number_of_blank_pose_right, number_of_blank_left_hand, number_of_blank_right_hand\n",
    "    global all_frames_pose_left, all_frames_pose_right, all_frames_left_hand, all_frames_right_hand\n",
    "    global pose_left, pose_right, left_hand, right_hand\n",
    "    \n",
    "    \n",
    "    varations = []\n",
    "    col = []\n",
    "    # creating vector of colmun\n",
    "    for it in range(len(all_frames_part[0])):\n",
    "        for frame in all_frames_part:\n",
    "            col.append(frame[it])\n",
    "        \n",
    "        # fixing zeros in whole 12 frame sequance\n",
    "        if fix_zeros:\n",
    "            for it2 in range(1, len(col)-1):\n",
    "                if(col[it2] == 0 and col[it2 + 1] == 0):\n",
    "                    # TO DO ... UPgrade global vector_of_blank_pose_left itd na 0 do wartosci it2 na 0, wtedy nie bd musial wchodzic tu nie potrzebnie\n",
    "                    return [404, 404]\n",
    "                if(col[it2] == 0):                            \n",
    "                    col[it2] = (col[it2 - 1] + col[it2 + 1])/2\n",
    "                    all_frames_part[it2][it] = col[it2]\n",
    "                    \n",
    "                    \n",
    "        #variation from every colmun\n",
    "        if check_varation:\n",
    "            # wyliczamy wariancje\n",
    "            col = 10 * np.array(col[:12]) # *10 working good for next if with treshold\n",
    "            srednio =  sum(col)/sequence_length \n",
    "            varations.append(np.sum( (np.array(col) - srednio)**2 ) / sequence_length )\n",
    "        col = []\n",
    "    \n",
    "    #counting varation and return if check varation\n",
    "    if check_varation:\n",
    "        if(np.sum(varations) >= 0.8):\n",
    "            return [1, 1]\n",
    "        else:\n",
    "            return [1, 404]\n",
    "    \n",
    "    # return for fixiing zeros\n",
    "    if(fix_zeros):\n",
    "        return [1, 404]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee73cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIC\n",
    "\n",
    "def extract_sequence(results):\n",
    "    \n",
    "    global frame_num, all_keypoints, left_zeros_fixed, right_zeros_fixed\n",
    "    global number_of_blank_pose_left, number_of_blank_pose_right, number_of_blank_left_hand, number_of_blank_right_hand\n",
    "    global vector_of_blank_pose_left, vector_of_blank_pose_right, vector_of_blank_left_hand, vector_of_blank_right_hand\n",
    "    global all_frames_pose_left, all_frames_pose_right, all_frames_left_hand, all_frames_right_hand\n",
    "    global pose_left, pose_right, left_hand, right_hand\n",
    "       \n",
    "    \n",
    "    # extracting keypoints\n",
    "    face, pose_left, pose_right, left_hand, right_hand = extract_keypoints(results)\n",
    "        \n",
    "    if len(face) == 0: # if there is no landmarks\n",
    "        print(\"there is nothing on sreen\")\n",
    "        init_global_variables_on_zero()\n",
    "        return 404\n",
    "    \n",
    "    # checking how many blanks is in every single part of body in last 12 frames\n",
    "    counting_number_of_blanks()  \n",
    "\n",
    "    # updating whole story for single part\n",
    "    update_all_frames()\n",
    "        \n",
    "    if(frame_num < 13):\n",
    "        frame_num += 1\n",
    "        return 404\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        lh = [404, 404]\n",
    "        lp = [404, 404]\n",
    "        ph = [404, 404]\n",
    "        pp = [404, 404]\n",
    "        # left hand and arm cant have more then 2 blanks frame and first analizng frame cant contain only zeros\n",
    "        if(number_of_blank_left_hand <= 2  and number_of_blank_pose_left <= 2 and all_frames_left_hand[0][0] != 0 and len(pose_left)-np.count_nonzero(all_frames_pose_left[0]) == 0):\n",
    "            # TO DO ...  uzyc flagi i jak mamy dobry wektor 12 klatek to updatowac tylko ostanie zmiany, jak byly 2 z rzedu fla na false by po jakims czasie naprawic caly wektor jak pojawia sie dobre dane\n",
    "            #if(left_zeros_fixed):\n",
    "            #    print(\"cos nowego\")\n",
    "            #else:\n",
    "            #    print(\"decyzja\")\n",
    "            lh = fixing_zeros_and_counting_varations(all_frames_left_hand)\n",
    "            lp = fixing_zeros_and_counting_varations(all_frames_pose_left)\n",
    "\n",
    "        # right hand and arm cant have more then 2 blanks frame and first analizng frame cant contain only zeros\n",
    "        if(number_of_blank_right_hand <= 2 and number_of_blank_pose_right <= 2 and  all_frames_right_hand[0][0] != 0 and len(pose_right)-np.count_nonzero(all_frames_pose_right[0]) == 0):\n",
    "            #if(right_zeros_fixed):\n",
    "            #    print(\"cos nowego\")\n",
    "            #else:\n",
    "            #    print(\"decyzja\")\n",
    "            ph = fixing_zeros_and_counting_varations(all_frames_right_hand)\n",
    "            pp = fixing_zeros_and_counting_varations(all_frames_pose_right)\n",
    "            \n",
    "        # not good data for prediction too much blanks frame\n",
    "            \n",
    "        # not good data for prediction -2 blanks next to eachother or too much blanks frame\n",
    "        if((lh[0] == 404 or lp[0] == 404) and (ph[0] == 404 or pp[0] == 404)):\n",
    "            print(\"coutch not enough landmarks \")\n",
    "            return 404\n",
    "           \n",
    "        # 2 hands are moving\n",
    "        elif(lh[1] == 1 and ph[1] == 1):\n",
    "            print(\"do sieci na 2 rece\")  # TO DO ... jak bd sie jebac moge polaczyc pose'y z soba i wyjebac jeden wspolny pnkt#####\n",
    "            for i in range(sequence_length):\n",
    "                keypoints = np.concatenate([all_frames_pose_left[i], all_frames_left_hand[i], all_frames_pose_right[i], all_frames_right_hand[i]])                                \n",
    "                all_keypoints.append(keypoints)\n",
    "            print()\n",
    "            return 2   \n",
    "        \n",
    "        # 1 hand is moving\n",
    "        elif(lh[1] == 1 or ph[1] == 1):\n",
    "            print(\"do sieci dla 1 reki\")\n",
    "            if(lh[1] == 1):\n",
    "                for i in range(sequence_length):                  \n",
    "                    keypoints = np.concatenate([all_frames_pose_left[i], all_frames_left_hand[i]])\n",
    "                    all_keypoints.append(keypoints)\n",
    "            else:\n",
    "                for i in range(sequence_length):\n",
    "                    keypoints = np.concatenate([all_frames_pose_right[i], all_frames_right_hand[i]])\n",
    "                    all_keypoints.append(keypoints) \n",
    "            print()\n",
    "            return 1\n",
    "        \n",
    "        # no move detected\n",
    "        else:\n",
    "            print(\"do sieci dla nie ruchomych rak\")                \n",
    "            all_keypoints = np.concatenate([sum(all_frames_pose_left)/sequence_length, sum(all_frames_left_hand)/sequence_length, sum(all_frames_pose_right)/sequence_length, sum(all_frames_right_hand)/sequence_length])\n",
    "            print()\n",
    "            return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f0b35",
   "metadata": {},
   "source": [
    "- importing model and setting dataset properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e62000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders info\n",
    "no_sequences = 50\n",
    "sequence_length = 12 \n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "actions = np.array(['pierdol_sie', 'hello','I_me','need','thanks', 'drink', 'beer'])\n",
    "colors = [(255, 153, 51) ,(245,117,16), (117,245,16), (16,117,245),(245,117,16), (117,245,16), (16,117,245)]\n",
    "\n",
    "# importing model\n",
    "model = keras.models.load_model(\"action2d_e25 _96.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff23bb",
   "metadata": {},
   "source": [
    " - vizualitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c60ff53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "do sieci dla 1 reki\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "do sieci dla 1 reki\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n",
      "coutch not enough landmarks \n"
     ]
    }
   ],
   "source": [
    "# init global variables\n",
    "init_global_variables_on_zero()\n",
    "sentence = []\n",
    "threshold = 0.9\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.4, min_tracking_confidence=0.4) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # read feed\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        # draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # extract sequence\n",
    "        network_choose= extract_sequence(results)\n",
    "        \n",
    "        \n",
    "        # choosing type of network\n",
    "        if network_choose == 0:\n",
    "            print()\n",
    "            # ------ ------- ------ ------ ------ ------ ------ \n",
    "            # TO DO ... siec na nieruchome obrazki\n",
    "            # ------ ------- ------ ------ ------ ------ ------         \n",
    "        \n",
    "        elif network_choose == 1: \n",
    "            \n",
    "            # making prediction\n",
    "            res = model.predict(np.expand_dims(all_keypoints, axis=0))[0]   \n",
    "            #print(actions[np.argmax(res)])\n",
    "            \n",
    "            # collecting 5 last words for top bar\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0:\n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # showing probabilities for every word\n",
    "            for num, prob in enumerate(res):\n",
    "                cv2.rectangle(image, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "                cv2.putText(image, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        elif network_choose == 2:\n",
    "            print()\n",
    "            # ------ ------- ------ ------ ------ ------ ------ \n",
    "            # TO DO ... siec na 2 lapy\n",
    "            # ------ ------- ------ ------ ------ ------ ------   \n",
    "        \n",
    "        # needed because of np concatenation\n",
    "        all_keypoints = [] \n",
    "        \n",
    "        # showing top bar\n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # show to screen\n",
    "        cv2.imshow('OpenCV ladnmark_test', image)\n",
    "\n",
    "        # break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8169d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siec na 2 lapy\n",
    "# zrobic dataset na 2 lapy\n",
    "# zrobic 3 blanki z rzedu to od nowa* zeby zer nie ciagnelo z poczatku jak jakas reka sie pojawi z ukrycia  \n",
    "# i nie byla wczesniej naprawiana to rozpierdala wariancje jak chcemy sie czegos pozbyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3db829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uczytelnic kod\n",
    "# - blocks of already exsiting functions DONE\n",
    "# - blocks of real time DONE\n",
    "# - - created func: DONE DONE DONE DONE DONE DONE\n",
    "# mozliwe ze trzeba zrobic osobny counter blankow dla obu rak, by pozbyc sie znaku zrobionego z poczatkowych 2 zer DONE\n",
    "\n",
    "# zrobic test data set\n",
    "# -na jedna reke DONE\n",
    "# -na 2 rece\n",
    "# przetestowac rozne sieci dla 2 sieci na jedna i 2 rece\n",
    "# -na jedna reke\n",
    "# -na 2 rece\n",
    "\n",
    "## na przyszlosc\n",
    "# normalizacja lecimy miedzy klata i twarza na 1 - wszystko co jest potrzebne jest w pobieranej dacie\n",
    "# mp holistic face false\n",
    "# dopracowac parametry \n",
    "# - wariancja jest w obu a przy tworzeniu ryja moge podciagnac zeby byl tip top i holistic dac duze wymagania zeby cos znalazl w real life na odwrot\n",
    "# - w pose dla 11 do 17 # to jeszcze do empirycznego ustawienia !!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c71d6",
   "metadata": {},
   "source": [
    "## training on PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946171eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14dac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(['pierdol_sie', 'hello','I_me','need','thanks', 'drink', 'beer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2676c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence+1), \"{}.npy\".format(frame_num+1)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "        \n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a565ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11/11 [==============================] - 4s 33ms/step - loss: 1.9257 - categorical_accuracy: 0.4096\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 1.7234 - categorical_accuracy: 0.6566\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 1.6273 - categorical_accuracy: 0.7169\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 1.0340 - categorical_accuracy: 0.6717\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6549 - categorical_accuracy: 0.7741\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.5960 - categorical_accuracy: 0.7952\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.8704 - categorical_accuracy: 0.7500\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.7233 - categorical_accuracy: 0.7440\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6545 - categorical_accuracy: 0.8253\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.5211 - categorical_accuracy: 0.8524\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3824 - categorical_accuracy: 0.8705\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3158 - categorical_accuracy: 0.8735\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2839 - categorical_accuracy: 0.8946\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2206 - categorical_accuracy: 0.9127\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2964 - categorical_accuracy: 0.8795\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2577 - categorical_accuracy: 0.8886\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.1812 - categorical_accuracy: 0.9187\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.1800 - categorical_accuracy: 0.9157\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1891 - categorical_accuracy: 0.9066\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1571 - categorical_accuracy: 0.9307\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1072 - categorical_accuracy: 0.9548\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0969 - categorical_accuracy: 0.9518\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1375 - categorical_accuracy: 0.9488\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1161 - categorical_accuracy: 0.9578\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1022 - categorical_accuracy: 0.9608\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 12, 64)            29440     \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 12, 128)           98816     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,135\n",
      "Trainable params: 184,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(12,50)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "#model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "#model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "#model.add(LSTM(128, return_sequences=True ,activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, y_train, epochs=25, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90b52c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action2d_e25 _96.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d278367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 ja         I ME (1 NIE)- https://www.handspeak.com/word/index.php?id=1086\n",
    "#2 ty         you (1 NIE)-  https://www.handspeak.com/word/index.php?id=2448\n",
    "!#3 on ono ana !HE (1)-     https://www.handspeak.com/word/index.php?id=1670\n",
    "#4 potrzobowac Need(2NIE)-  https://www.handspeak.com/word/index.php?id=1471\n",
    "#5 pomoc      Help(2)-      https://www.handspeak.com/word/index.php?id=1017\n",
    "#6 chce       Want(2)-      https://www.handspeak.com/word/index.php?id=2347\n",
    "#7 prosze     Pleas(2)-     https://www.handspeak.com/word/index.php?id=1658\n",
    "#8 dziekuje   Thank(1)-     https://www.handspeak.com/word/index.php?id=2186\n",
    "#9 gdzie      Where(1 NIE)- https://www.handspeak.com/word/index.php?id=2391\n",
    "#10 jest      is(1)-        https://www.handspeak.com/word/index.php?id=10338\n",
    "#11 bolec     Hurt(2)-      https://www.handspeak.com/word/index.php?id=1077\n",
    "#12 dusic sie Choke(1 NIE)- https://www.handspeak.com/word/index.php?id=5584\n",
    "#13 spragniony Thirsty(1)-  https://www.handspeak.com/word/index.php?id=2205\n",
    "#14 glodny     hungry(1)-   https://www.handspeak.com/word/index.php?id=1076\n",
    "#14.5 jesc     eat(1 NIE)-  https://www.handspeak.com/word/index.php?id=645\n",
    "#15 zmarzniety cold(2)-     https://www.handspeak.com/word/index.php?id=645\n",
    "#16 resustytacja RESUSCITATION(2) https://www.handspeak.com/word/index.php?id=5154\n",
    "#17 zemdlal    blackout (1) https://www.handspeak.com/word/index.php?id=5618\n",
    "!#18 cukrzyk    diabetic (1) https://www.handspeak.com/word/index.php?id=1092\n",
    "#19 zlamal :)   broke (1)-  https://www.handspeak.com/word/index.php?id=263\n",
    "#20 reka        arm(1)    https://www.handspeak.com/word/index.php?id=105\n",
    "#21 noga!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#22 uderzyc    hit(2)- https://www.handspeak.com/word/index.php?id=1037\n",
    "#23 glowa\n",
    "#24 krwawi\n",
    "#25 wypadek\n",
    "#26 karetka\n",
    "#27 zadzwon\n",
    "#28 pic\n",
    "#29 porazony pradem\n",
    "#30 skelpie\n",
    "#31 ulicy\n",
    "#32 w\n",
    "#33 na\n",
    "#34 przy\n",
    "#35 na pasach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
